<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xml" href="http://localhost:4000/feed.xslt.xml"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="http://jekyllrb.com" version="3.4.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-03-07T16:46:43+08:00</updated><id>http://localhost:4000//</id><title type="html">Hi, I’m Wang qinxiao</title><subtitle>读有趣的书，做有趣的事。
</subtitle><author><name>by 王勤晓</name></author><entry><title type="html">朴素贝叶斯算法</title><link href="http://localhost:4000/jekyll/update/2020/03/05/NAIVE-BAYES.html" rel="alternate" type="text/html" title="朴素贝叶斯算法" /><published>2020-03-05T16:46:00+08:00</published><updated>2020-03-05T16:46:00+08:00</updated><id>http://localhost:4000/jekyll/update/2020/03/05/NAIVE-BAYES</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2020/03/05/NAIVE-BAYES.html">&lt;p&gt;朴素贝叶斯是一种分类算法，常用于垃圾邮件识别和文本分类。如果想要一个易于理解、快速的分类器，那么朴素贝叶斯会是首选。&lt;/p&gt;

&lt;p&gt;朴素贝叶斯基于贝叶斯提出的贝叶斯定理，并且假设样本特征彼此独立，没有相关关系，而这个假设在现实世界中是很不真实的，这很“朴素（NAIVE）”，朴素贝叶斯因此得名。&lt;/p&gt;

&lt;h2 id=&quot;贝叶斯分类应用示例&quot;&gt;贝叶斯分类应用示例&lt;/h2&gt;
&lt;p&gt;本例来自阮一峰的&lt;a href=&quot;http://www.ruanyifeng.com/blog/2013/12/naive_bayes_classifier.html&quot;&gt;《朴素贝叶斯分类器的应用》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;某个医院早上收了六个门诊病人，统计数据如下表：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;症状&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;职业&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;疾病&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;打喷嚏&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;护士　&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;　感冒&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;打喷嚏&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;农夫　　&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;　过敏&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;头痛&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;建筑工人　&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;脑震荡&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;头痛&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;建筑工人　&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;感冒&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;打喷嚏&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;教师　&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;　感冒&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;头痛&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;教师　&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;脑震荡&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;现在又来了第七个病人，是一个打喷嚏的建筑工人。计算他患上感冒的概率有多大。&lt;/p&gt;

&lt;p&gt;根据贝叶斯定理：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;P(A|B) = P(B|A)P(A) / P(B)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;可得：&lt;code class=&quot;highlighter-rouge&quot;&gt;P(感冒|打喷嚏x建筑工人) = P(打喷嚏x建筑工人|感冒) x P(感冒) / P(打喷嚏x建筑工人)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;假定”打喷嚏”和”建筑工人”这两个特征是独立的，则：&lt;code class=&quot;highlighter-rouge&quot;&gt;P(感冒|打喷嚏x建筑工人) = P(打喷嚏|感冒) x P(建筑工人|感冒) x P(感冒) / P(打喷嚏) x P(建筑工人) = 0.66 x 0.33 x 0.5 / 0.5 x 0.33 = 0.66&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;因此，这个打喷嚏的建筑工人，有66%的概率是得了感冒。同理，可以计算这个病人患上过敏或脑震荡的概率。比较这几个概率，就可以知道他最可能得什么病。&lt;/p&gt;

&lt;p&gt;这就是贝叶斯分类器的基本方法：在统计资料的基础上，依据某些特征，计算各个类别的概率，从而实现分类。&lt;/p&gt;

&lt;h2 id=&quot;算法原理&quot;&gt;算法原理&lt;/h2&gt;
&lt;p&gt;根据概率知识，已知：
&lt;img src=&quot;http://localhost:4000/assets/images/PAB.png&quot; alt=&quot;PAB&quot; /&gt;，
&lt;img src=&quot;http://localhost:4000/assets/images/PBA.png&quot; alt=&quot;PBA&quot; /&gt;&lt;/p&gt;

&lt;p&gt;合并公式，则==&amp;gt;
&lt;img src=&quot;http://localhost:4000/assets/images/PABfinal.png&quot; alt=&quot;BAYES&quot; /&gt;，即贝叶斯定理。&lt;/p&gt;

&lt;p&gt;贝叶斯定理中，A是标签，B是属性集合。假定B属性集合中的属性（B1,B2,B3…Bi）彼此独立，则，&lt;code class=&quot;highlighter-rouge&quot;&gt;P(A|B) = P(B1|A) x P(B2|A) x P(B3|A)...x P(Bi|A) x P(A) / P(B1) x P(B2) x P(B3)...x P(Bi)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;在分类的过程中，由于P(B1) x P(B2) x P(B3)…x P(Bi)的值在求各类的概率时都是一样，所以在计算时可去掉此常数，简化为：&lt;code class=&quot;highlighter-rouge&quot;&gt;P(A|B) = P(B1|A) x P(B2|A) x P(B3|A)...x P(Bi|A) x P(A)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;以上公式中各项都可以从训练样本中统计而得。&lt;/p&gt;

&lt;h2 id=&quot;算法优缺点&quot;&gt;算法优缺点&lt;/h2&gt;
&lt;p&gt;优点：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;计算简单，快速。统计各类别的概率，计算并不复杂。&lt;/li&gt;
  &lt;li&gt;易理解。计算各个类别的概率，从而实现分类，概率这一概念也容易被人理解。&lt;/li&gt;
  &lt;li&gt;对离散类型的属性效果很好，比如文本分类。&lt;/li&gt;
  &lt;li&gt;具有高维数据的良好性能（特征数量很大）。&lt;/li&gt;
  &lt;li&gt;可以有效地进行多类预测。&lt;/li&gt;
  &lt;li&gt;对无关特征不敏感。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;缺点：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;不太适合处理连续型的属性。需要将连续型数据离散化，效果不一。&lt;/li&gt;
  &lt;li&gt;特征的独立性不成立。现实生活中，各属性完全独立的情况很少。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;———本文结束&lt;/p&gt;

&lt;p&gt;［参考文档］&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.ruanyifeng.com/blog/2013/12/naive_bayes_classifier.html&quot;&gt;阮一峰的《朴素贝叶斯分类器的应用》&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>by 王勤晓</name></author><summary type="html">朴素贝叶斯是一种分类算法，常用于垃圾邮件识别和文本分类。如果想要一个易于理解、快速的分类器，那么朴素贝叶斯会是首选。</summary></entry><entry><title type="html">《“黑客”一词》</title><link href="http://localhost:4000/jekyll/update/2019/09/15/attitude.html" rel="alternate" type="text/html" title="《“黑客”一词》" /><published>2019-09-15T16:20:00+08:00</published><updated>2019-09-15T16:20:00+08:00</updated><id>http://localhost:4000/jekyll/update/2019/09/15/attitude</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2019/09/15/attitude.html">&lt;p&gt;《“黑客”一词》（The Word “Hacker”）是《黑客与画家》书中的一篇文章，讲述黑客文化。本文不讨论该文思想，只记录几个有所启发的句子。&lt;/p&gt;

&lt;p&gt;1.&lt;code class=&quot;highlighter-rouge&quot;&gt;Show any hacker a lock and his first thought is how to pick it.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;黑客看到一个锁的第一个反应是撬开它。黑客或极客都喜欢挑战各种规则，崇尚自由，讨厌条条框框的限制。互联网的繁荣与黑客精神密不可分。&lt;/p&gt;

&lt;p&gt;2.&lt;code class=&quot;highlighter-rouge&quot;&gt;Hackers are unruly. That is the essence of hacking. And it is also the essence of Americanness. It is no accident that Silicon Valley is in America, and not France, or Germany, or England, or Japan. In those countries, people color inside the lines.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;黑客都是不服从管教的，这事黑客的本性。这也是美国人的本性。所以硅谷出现在了美国，而不是欧洲、日本，因为那里的人都在按部就班的生活。不服从管教的文化不一定就能诞生黑客精神，但这种文化是黑客的必要条件。另一个主要因素应该是经济基础。而美国恰恰都具备了，因此吸引了全球的黑客人才。&lt;/p&gt;

&lt;p&gt;3.&lt;code class=&quot;highlighter-rouge&quot;&gt;It's odd that people think of programming as precise and methodical. Computers are precise and methodical. Hacking is something you do with a gleeful laugh.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;人们往往认为编程是精确、模式化的。计算机的确是精确、模式化的。但是黑客的工作，并非按部就班，更多的是会心一笑。精确的计算机世界其核心是自由和创新。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.paulgraham.com/gba.html&quot;&gt;原文地址&lt;/a&gt;&lt;/p&gt;</content><author><name>by 王勤晓</name></author><summary type="html">《“黑客”一词》（The Word “Hacker”）是《黑客与画家》书中的一篇文章，讲述黑客文化。本文不讨论该文思想，只记录几个有所启发的句子。</summary></entry><entry><title type="html">K-means</title><link href="http://localhost:4000/jekyll/update/2019/09/13/kmeans.html" rel="alternate" type="text/html" title="K-means" /><published>2019-09-13T18:30:00+08:00</published><updated>2019-09-13T18:30:00+08:00</updated><id>http://localhost:4000/jekyll/update/2019/09/13/kmeans</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2019/09/13/kmeans.html">&lt;p&gt;K-means（K-均值）算法是十大数据挖掘算法之一，用于聚类。它可以通过无监督的方式将样本数据中相似的数据聚在一起。&lt;/p&gt;

&lt;h2 id=&quot;历史&quot;&gt;历史&lt;/h2&gt;
&lt;p&gt;K-means历史悠久，最早可追溯到Lloyd在1956年的研究。&lt;/p&gt;

&lt;h2 id=&quot;算法原理&quot;&gt;算法原理&lt;/h2&gt;
&lt;p&gt;K-means算法步骤如下：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;首先随机选取K个点作为聚类的初始中心点。&lt;/li&gt;
  &lt;li&gt;计算每个数据点到各个中心点的距离，找到距离自己最近的中心点，聚到该簇。&lt;/li&gt;
  &lt;li&gt;更新各个聚类数据集合的中心点，算法是计算该簇各个点坐标的的均值，。&lt;/li&gt;
  &lt;li&gt;重复步骤2、3的步骤，直到算法收敛。算法收敛的标准一般是K个聚类中每个数据点到中心点的距离总和最小，或中心点不再发生变化。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;聚类的目标，即收敛需要一个目标函数，K-means使用误差的平方和（Sum of the Squared Error，SSE）作为度量聚类质量的目标函数。计算每个数据点的误差，即数据点到中心点的欧几里德距离（直线距离），然后计算误差的平方和。对比两次聚类结果，SSE越小越好。&lt;/p&gt;

&lt;h2 id=&quot;k-means缺点&quot;&gt;K-means缺点&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;不能处理非球形簇、不同密度簇、尺寸不同的簇。&lt;/li&gt;
  &lt;li&gt;聚类的个数和初始中心点需要人为指定，K值有时很难估计，初始的中心点不同有时结果差异很大。&lt;/li&gt;
  &lt;li&gt;只限于有中心概念的数据。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;变种算法&quot;&gt;变种算法&lt;/h2&gt;
&lt;p&gt;K－means有一些变种算法，例如K-means++，二分K-means，能在一定程度上减少初始中心的影响。K-means在初始中心点尽量让各个中心点距离较远，二分K-means会先通过K-means算法分为两簇，然后再对各簇分别进行聚类。&lt;/p&gt;

&lt;p&gt;———本文结束&lt;/p&gt;

&lt;p&gt;［参考文档］&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/58907c0e0024&quot;&gt;https://www.jianshu.com/p/58907c0e0024&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;《数据挖掘导论》&lt;/li&gt;
&lt;/ol&gt;</content><author><name>by 王勤晓</name></author><summary type="html">K-means（K-均值）算法是十大数据挖掘算法之一，用于聚类。它可以通过无监督的方式将样本数据中相似的数据聚在一起。</summary></entry><entry><title type="html">《不能说的话》</title><link href="http://localhost:4000/jekyll/update/2019/09/08/what-you-can't-say.html" rel="alternate" type="text/html" title="《不能说的话》" /><published>2019-09-08T17:30:00+08:00</published><updated>2019-09-08T17:30:00+08:00</updated><id>http://localhost:4000/jekyll/update/2019/09/08/what-you-can't-say</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2019/09/08/what-you-can't-say.html">&lt;p&gt;《不能说的话》（What You Can’t Say）是《黑客与画家》书中的一篇文章。本文不讨论该文思想，只记录几个有所启发的句子。&lt;/p&gt;

&lt;p&gt;1.&lt;code class=&quot;highlighter-rouge&quot;&gt;The statements that make people mad are the ones they worry might be believed. I suspect the statements that make people maddest are those they worry might be true.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;人们不喜欢听的话其实往往是他们相信的话。如果一句话使对方反应越大，说明他越相信会是真的。“身正不怕影子歪”，“欲盖弥彰”也是这个道理。测试一个人或对方是否心虚，可以用这种方法。&lt;/p&gt;

&lt;p&gt;2.&lt;code class=&quot;highlighter-rouge&quot;&gt;Great work tends to grow out of ideas that others have overlooked, and no idea is so overlooked as one that's unthinkable.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;优秀的作品往往来自被人忽视的想法，而最被人忽视的想法就是那些被禁止的想法。纵观古今中外历史，唯有思想开发包容的时代，才能产生优秀的文化作品。随着中国思想环境的逐渐开放，庞大的人民群众的智慧会自然爆发出惊人的作品（现在已有苗头），中国文化软实力才能真正发展。精英政治有一定的道理，但文化主要还是自下而上产生于民间。&lt;/p&gt;

&lt;p&gt;3.&lt;code class=&quot;highlighter-rouge&quot;&gt;Whatever the reason, there seems a clear correlation between intelligence and willingness to consider shocking ideas. This isn't just because smart people actively work to find holes in conventional thinking. I think conventions also have less hold over them to start with. You can see that in the way they dress.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;智力越高的人越愿意去思考惊世骇俗的观点。他们更主动的去发现传统观念的漏洞，而且传统观念对他们的影响也很小，这一点从衣着上就可以看出。有智慧的人在于其有独立思考的能力，敢于挑战常规，不轻易受舆论煽动和大众观念裹挟。&lt;/p&gt;

&lt;p&gt;4.&lt;code class=&quot;highlighter-rouge&quot;&gt;The most important thing is to be able to think what you want, not to say what you want. And if you feel you have to say everything you think, it may inhibit you from thinking improper thoughts。&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;思想应该无所限制，但不能口无遮拦，否则惹祸上身。思想是属于自己的，可以天马行空，但说话涉及社交，社交就涉及妥协。凡事无绝对，掌握界限和度是重要，这就是一个哲学问题了（我似乎明白了为什么国外博士学位都叫Doctor of Philosophy）。&lt;/p&gt;

&lt;p&gt;5.&lt;code class=&quot;highlighter-rouge&quot;&gt;Smile at everyone, and don't tell them what you're thinking. This was wise advice.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;守口如瓶，笑脸相迎。同上，世界很危险，不能乱说话，不能被人轻易看透。&lt;/p&gt;

&lt;p&gt;6.&lt;code class=&quot;highlighter-rouge&quot;&gt;One way to do this is to ratchet the debate up one level of abstraction. If you argue against censorship in general, you can avoid being accused of whatever heresy is contained in the book or film that someone is trying to censor. You can attack labels with meta-labels: labels that refer to the use of labels to prevent discussion. The spread of the term &quot;political correctness&quot; meant the beginning of the end of political correctness, because it enabled one to attack the phenomenon as a whole without being accused of any of the specific heresies it sought to suppress.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;守口如瓶，不意味着什么都不能说，在说一些危险的话时可以用到一些技巧。一种技巧是比如将问题抽象。例如反驳审查制度，不能就具体的书或电影辩论，否则会被认为是支持该书或电影。提取元标签，即抽象的描述，如“政治正确”。总之，要直击问题的本质，不要被带沟里去了。&lt;/p&gt;

&lt;p&gt;7.&lt;code class=&quot;highlighter-rouge&quot;&gt;Another way to counterattack is with metaphor. Arthur Miller undermined the House Un-American Activities Committee by writing a play, &quot;The Crucible,&quot; about the Salem witch trials. He never referred directly to the committee and so gave them no way to reply. What could HUAC do, defend the Salem witch trials? And yet Miller's metaphor stuck so well that to this day the activities of the committee are often described as a &quot;witch-hunt.&quot;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;第二种说一些禁忌的话的方法是使用隐喻。《动物庄园》使用动物反抗来隐喻人类革命，当时读书时对我的震撼要比《1984》这种直接描写要强烈的多。&lt;/p&gt;

&lt;p&gt;8.&lt;code class=&quot;highlighter-rouge&quot;&gt;Best of all, probably, is humor. Zealots, whatever their cause, invariably lack a sense of humor. They can't reply in kind to jokes.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;最好的一种办法，可能是幽默。狂热极端分子最不擅长的就是幽默。使用幽默出击，对方往往无还手之力。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.paulgraham.com/say.html&quot;&gt;What You Can’t Say 原文地址&lt;/a&gt;&lt;/p&gt;</content><author><name>by 王勤晓</name></author><summary type="html">《不能说的话》（What You Can’t Say）是《黑客与画家》书中的一篇文章。本文不讨论该文思想，只记录几个有所启发的句子。</summary></entry><entry><title type="html">决策树算法 ID3, C4.5, CART</title><link href="http://localhost:4000/jekyll/update/2019/09/07/ID3.html" rel="alternate" type="text/html" title="决策树算法 ID3, C4.5, CART" /><published>2019-09-07T18:30:00+08:00</published><updated>2019-09-07T18:30:00+08:00</updated><id>http://localhost:4000/jekyll/update/2019/09/07/ID3</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2019/09/07/ID3.html">&lt;p&gt;决策树通过不断的特征二分决策，给出样本的类别。在这一过程中，有三个核心步骤：1.节点（特征，也称属性）的选择及节点顺序。2.节点如何划分。3.剪枝，剔除多余的分支，形成最终的树。决策树经典算法ID3，C4.5和CART的主要区别在第一个步骤，即特征的选择和使用顺序上用到的算法不同。&lt;/p&gt;

&lt;h2 id=&quot;id3-基于信息增益&quot;&gt;ID3-基于信息增益&lt;/h2&gt;
&lt;p&gt;ID3（Iterative Dichotomiser 3，迭代二分器三代）由罗斯昆（J.R.Quinlan）1975年在悉尼大学提出了ID3算法。该算法基于香农（Shannon C E.）在信息论中提出的信息熵的概念。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;信息熵表示信息量的度量，熵越大，表示可能发生的结果越多，不确定性越高。在分类场景中，对于一堆样本数据，如果信息熵高说明种类多，纯度越低，相反则种类少，纯度越高。对于特征数据，信息熵越小说明该特征分类后的纯度越高，对分类系统越有效。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;为了更直观的理解，可将信息熵转化为信息增益。ID3算法将特征的信息增益作为特征选取顺序的依据。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;信息增益表示某个特征能够为分类带来多少“信息”。信息增益越高，表示该特征为分类提供的信息越多。如计算瓜蒂形状的信息增益 ＝ 样本数据总的信息熵 － 瓜蒂分类后的信息熵。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;信息熵，信息增益的公式如下：
&lt;img src=&quot;http://localhost:4000/assets/images/INFORMATIONH.png&quot; alt=&quot;INFORMATIONH&quot; /&gt;&lt;/p&gt;

&lt;p&gt;关于信息熵和信息增益，推荐&lt;a href=&quot;https://www.jianshu.com/p/69dbb042a0e3&quot;&gt;https://www.jianshu.com/p/69dbb042a0e3&lt;/a&gt;中例子，很直观。&lt;/p&gt;

&lt;p&gt;ID3使用信息增益来进行特征的选择，存在的问题是，属性值多的指标（如身份证号）往往信息增益会大，因此在选择时对于多属性值的特征有偏好。&lt;/p&gt;

&lt;h2 id=&quot;c45基于信息增益率&quot;&gt;C4.5－基于信息增益率&lt;/h2&gt;
&lt;p&gt;罗斯昆在自己的ID3算法基础上进行扩展，提出了C4.5算法。C4.5也是基于信息熵的概念，与ID3不同是，使用了信息增益率。信息增益率在评估特征时，把属性值的数量也考虑了进去，从而避免了属性值过多影响判断的问题。&lt;/p&gt;

&lt;p&gt;特征属性值数目越多，则IV(a)的值越大，信息增益率越小，一定程度上削弱了“对属性值多的特征”的偏好，但是同时也可能出现“对属性值少的特征”的偏好的问题。&lt;/p&gt;

&lt;h2 id=&quot;c45基于基尼指数&quot;&gt;C4.5－基于基尼指数&lt;/h2&gt;

&lt;p&gt;CART（Classification And Regression Tree，分类回归树）Leo Breiman, Jerome Friedman, Richard Olshen与Charles Stone于1984年提出。CART和ID3、C4.5算法不同的之处在于：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;ID3、C4.5算法都是基于信息熵来进行划分节点选取，主要用于分类问题，分类和回归问题都可以使用。本文直讨论分类。&lt;/li&gt;
  &lt;li&gt;在节点划分时，只做二元划分。比如特征颜色取值红、黄、蓝，ID3和C4.5直接就划分为红、黄、蓝三个子类，而CART会划分为｛红｝和｛黄、蓝｝，或者｛红，黄｝和｛蓝｝，穷举所有组合。这样的好处是可以避免特征属性值数目多少的偏好问题。但准确率会有所降低。&lt;/li&gt;
  &lt;li&gt;CART划分的标准是使用基尼指数。当样本越不均匀，基尼指数越小。因此，我们可以先选取划分后基尼指数最小的特征（最能够区分样本）进行划分。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;基尼指数公式如下：
&lt;img src=&quot;http://localhost:4000/assets/images/GINI.SVG&quot; alt=&quot;GINI&quot; /&gt;&lt;/p&gt;

&lt;p&gt;例如，一个节点N划分后，子节点a中类0为1个，类1为5个，子节点b中类0为4个，类1为1个，则Gini(N
) ＝ |a|/|N|&lt;em&gt;Gini(a) + |b|/|N|&lt;/em&gt;Gini(b) = 6/11&lt;em&gt;(1-((1/6)&lt;/em&gt;(1/6)+(5/6)&lt;em&gt;(5/6))) + 5/11&lt;/em&gt;(1-((4/5)&lt;em&gt;(4/5)+(1/5)&lt;/em&gt;(1/5)))&lt;/p&gt;

&lt;p&gt;———本文结束&lt;/p&gt;

&lt;p&gt;［参考文档］&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/69dbb042a0e3&quot;&gt;https://www.jianshu.com/p/69dbb042a0e3&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/27313529&quot;&gt;https://zhuanlan.zhihu.com/p/27313529&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;《数据挖掘导论》&lt;/li&gt;
&lt;/ol&gt;</content><author><name>by 王勤晓</name></author><summary type="html">决策树通过不断的特征二分决策，给出样本的类别。在这一过程中，有三个核心步骤：1.节点（特征，也称属性）的选择及节点顺序。2.节点如何划分。3.剪枝，剔除多余的分支，形成最终的树。决策树经典算法ID3，C4.5和CART的主要区别在第一个步骤，即特征的选择和使用顺序上用到的算法不同。</summary></entry><entry><title type="html">数据挖掘算法－决策树</title><link href="http://localhost:4000/jekyll/update/2019/09/01/DecisionTree..html" rel="alternate" type="text/html" title="数据挖掘算法－决策树" /><published>2019-09-01T21:30:00+08:00</published><updated>2019-09-01T21:30:00+08:00</updated><id>http://localhost:4000/jekyll/update/2019/09/01/DecisionTree.</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2019/09/01/DecisionTree..html">&lt;p&gt;决策树（Decision Tree）是十大经典数据挖掘／机器学习算法，用于分类和回归。本文主要讨论分类。&lt;/p&gt;

&lt;p&gt;决策树算法用于将样本进行分类（通常二分类）。例如，著名的西瓜例子，根据瓜蒂形状、瓜皮颜色、敲瓜声音等特征，反复进行二分决策（瓜蒂卷的是好瓜，否则看瓜皮-瓜皮深的是好瓜，否则再听声音……），从而分类好瓜还是坏瓜。该算法决策的流程画出来像一颗倒置得树，因此得名“决策树”。&lt;/p&gt;

&lt;p&gt;决策树算法在分类领域应用广泛，并再此基础上衍生了随机森林等经典数据挖掘算法。包含策树的典型算法有ID3、C4.5、CART等。ID3和C4.5用于分类，CART可用于分类与回归。具体算法另有文章讨论，本文只讨论决策树的核心思想。&lt;/p&gt;

&lt;h3 id=&quot;决策树构建&quot;&gt;决策树构建&lt;/h3&gt;

&lt;p&gt;决策树算法的关键在于树（即分类规则）的构建，其核心步骤包括：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;节点（特征，也称属性）的选择及节点（特征）顺序。（第一步，先判断瓜蒂形状、瓜皮颜色还是敲瓜声音；第二步……）&lt;/li&gt;
  &lt;li&gt;节点如何划分。(根据瓜蒂形状如何进行先一步判断，例如瓜蒂卷，是好瓜，否则看瓜皮……)。&lt;/li&gt;
  &lt;li&gt;剪枝。去掉多余的叶结点（分类结果），使其回退到父结点（特征），甚至更高的结点，然后将父结点或更高的结点改为新的叶结点。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;步骤1涉及到具体的算法，ID3，C4.5，CART各不相同：ID3使用信息增益，C4.5使用信息增益比，CART使用基尼指数。具体问题另有文章分别讨论。&lt;/p&gt;

&lt;p&gt;步骤2节点划分。节点的数据分为离散数据和连续数据，在处理离散数据时，可以将对应的属性值作为分支，或分组输出。在处理连续数据时，需要找到最佳划分点。例如一个特征的属性值范围是1-100，那么到底选择哪个点进行分类划分最为合理？&lt;/p&gt;

&lt;h3 id=&quot;最佳划分&quot;&gt;最佳划分&lt;/h3&gt;
&lt;p&gt;选择最佳划分的度量通常是根据划分后的子节点的纯度。纯度越高，说明划分后的分类越倾斜，也就越能达到分类的目的。纯度的度量一般可以用熵、基尼指数或分类误差。&lt;/p&gt;

&lt;p&gt;熵的值范围为0-1，基尼指数和分类误差值范围为0-0.5。&lt;/p&gt;

&lt;p&gt;步骤3可分为预剪枝和后剪枝，其目的是简化树，使其具有更好的泛化能力，避免过拟合。&lt;/p&gt;

&lt;h3 id=&quot;预剪枝&quot;&gt;预剪枝&lt;/h3&gt;
&lt;p&gt;预剪枝的思想是在构造决策树的同时进行剪枝，即在创建之前，先计算当前的划分是否能提升模型的泛化能力，如果不能的话，就不再创建分支，直接给出叶子节点（分类结果）。常见的预剪枝方法有：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;当决策树达到一定的深度的时候，停止分支；&lt;/li&gt;
  &lt;li&gt;当到达当前节点的样本数量小于某个阈值的时候，停止分支；&lt;/li&gt;
  &lt;li&gt;计算决策树每一次分裂对测试集的准确度是否提升，当没有提升或者提升程度小于某个阈值的时候，则停止分支；&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;后剪枝&quot;&gt;后剪枝&lt;/h3&gt;
&lt;p&gt;后剪枝是在决策树生长完成之后，对树进行剪枝，得到简化版的决策树。常见的后剪枝方法有：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;判断分支的熵的增加量是否小于某一阈值。如果是，则剪枝。&lt;/li&gt;
  &lt;li&gt;用测试集进行判断，如果某分支剪掉后的准确率有所提升或者没有降低，就剪枝。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;优点和局限&quot;&gt;优点和局限&lt;/h3&gt;

&lt;p&gt;优点：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;较随机森林可解释性，性能好。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;缺点：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;容易过拟合。&lt;/li&gt;
  &lt;li&gt;样本特征独立，忽略了特征之间的相关性。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;———本文结束&lt;/p&gt;

&lt;p&gt;［参考文档］&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/luban/p/9412339.html&quot;&gt;https://www.cnblogs.com/luban/p/9412339.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Oscar6280868/article/details/86158170&quot;&gt;https://blog.csdn.net/Oscar6280868/article/details/86158170&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>by 王勤晓</name></author><summary type="html">决策树（Decision Tree）是十大经典数据挖掘／机器学习算法，用于分类和回归。本文主要讨论分类。</summary></entry><entry><title type="html">关于自律</title><link href="http://localhost:4000/jekyll/update/2019/08/25/self-discipline.html" rel="alternate" type="text/html" title="关于自律" /><published>2019-08-25T23:00:00+08:00</published><updated>2019-08-25T23:00:00+08:00</updated><id>http://localhost:4000/jekyll/update/2019/08/25/self-discipline</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2019/08/25/self-discipline.html">&lt;p&gt;自律能帮助我们去掉不好的习惯，把精力更高效地投入到对自己有益的事情上。人人都知道自律是好的，但每个人自律的目的不一样。马云的自律和一位中学生自律的目的就不一样。&lt;/p&gt;

&lt;p&gt;近期发现，我自律的目的是为了获取安全感。自律学习是为了能保住工作，不至于失业；自律健身是为了健康，不至于猝死。&lt;/p&gt;

&lt;p&gt;根据马斯洛需求层次理论，人类需求像阶梯一样从低到高按层次分为五种，分别是：生理需求、安全需求、社交需求、尊重需求和自我实现需求。这样来看，我还处在第二层：我当前一切活动的主要目的还是为了实现安全需求，偶尔涉及更高层。&lt;/p&gt;

&lt;p&gt;对于芸芸大众来说，安全需求应该是最难实现的一层需求。财务自由是是实现安全需求最直接的方法，但赚钱是这个世上最难的事情之一（除了马云认为“赚钱是这个世上最简单的事”）。&lt;/p&gt;

&lt;p&gt;我的自律就是为了持续赚更多的钱，以满足我的安全需求。如此，才能有机会实现后面更高层的需求。&lt;/p&gt;

&lt;p&gt;———本文结束&lt;/p&gt;</content><author><name>by 王勤晓</name></author><summary type="html">自律能帮助我们去掉不好的习惯，把精力更高效地投入到对自己有益的事情上。人人都知道自律是好的，但每个人自律的目的不一样。马云的自律和一位中学生自律的目的就不一样。</summary></entry><entry><title type="html">数据挖掘算法－随机森林</title><link href="http://localhost:4000/jekyll/update/2019/08/25/RF.html" rel="alternate" type="text/html" title="数据挖掘算法－随机森林" /><published>2019-08-25T11:30:00+08:00</published><updated>2019-08-25T11:30:00+08:00</updated><id>http://localhost:4000/jekyll/update/2019/08/25/RF</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2019/08/25/RF.html">&lt;p&gt;随机森林（Random Forest，简称RF）是十大经典数据挖掘／机器学习算法，用于分类和回归。本文主要讨论分类。&lt;/p&gt;

&lt;h3 id=&quot;应用场景&quot;&gt;应用场景&lt;/h3&gt;

&lt;p&gt;了解一个算法，应该从其应用开始。&lt;/p&gt;

&lt;p&gt;RF算法用于将样本进行分类（通常二分类）。例如，笔者在帮助运营商识别潜在离网用户（目的是将用户分为将要离网OR不离网两类）中就使用了RF算法。&lt;/p&gt;

&lt;p&gt;RF算法的使用分为训练和推理两个阶段。&lt;/p&gt;

&lt;p&gt;训练阶段，输入训练数据集，即各种指标＋标签，如“用户类型，使用时长，网络质量等等 ＋ 是否离网标签“，经过RF算法训练，输出模型（发现的特征规律）。训练后的模型可反复使用。&lt;/p&gt;

&lt;p&gt;推理阶段，输入样本数据，经过训练阶段输出的RF模型识别，得到样本类别。&lt;/p&gt;

&lt;p&gt;RF算法在分类领域应用广泛。&lt;/p&gt;

&lt;h3 id=&quot;发展历史&quot;&gt;发展历史&lt;/h3&gt;

&lt;p&gt;随机森林算法是基于决策树算法改进而来。上世纪八十年代Breiman等人发明了决策树算法，通过反复二分数据进行分类，例如通过西瓜数据判断好瓜坏瓜，先看瓜皮颜色深还是浅，然后看瓜蒂是否卷曲，直到得到分类结果。决策树算法这里暂不深入讲解。&lt;/p&gt;

&lt;p&gt;2001年Breiman把多棵决策树组合成随机森林。随机森林顾名思义，该森林里面有很多的决策树，构造树的数据选择是随机的。进行分类时，输入样本进入森林，森林中的每一棵决策树对样本进行判断，看看这个样本应该属于哪一类，得票数最多的一类为最终分类结果。&lt;/p&gt;

&lt;p&gt;与决策树相比，随机森林在运算量没有显著提高的前提下提高了预测精度(其随机性解决过拟合问题)。&lt;/p&gt;

&lt;h3 id=&quot;工作原理&quot;&gt;工作原理&lt;/h3&gt;

&lt;p&gt;训练：RF使用多棵决策树，在构建每棵决策树时，对训练集进行随机且有放回地采样（bootstrap sample）。&lt;/p&gt;

&lt;p&gt;推理：RF训练出的模型包括多棵决策树，每棵决策树都是一个分类器，那么对于一个输入样本，N棵树会有N个分类结果。根据分类投票结果，将得票数最多的类别指定为最终输出，或者输出样本属于每个类别的概率。&lt;/p&gt;

&lt;p&gt;这种使用Boostrap采样方法，结合几个模型降低泛化误差的技术思想（避免过拟合），称为Bagging（Bootstrap aggregating）。&lt;/p&gt;

&lt;h3 id=&quot;优点和局限&quot;&gt;优点和局限&lt;/h3&gt;

&lt;p&gt;优点：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;在训练阶段，随机选择数据行和列，对于多特征、不平衡、特征遗失数据，效果良好。可不用做特征选择。&lt;/li&gt;
  &lt;li&gt;（较神经网络）运算量低，（较决策树）精度高。&lt;/li&gt;
  &lt;li&gt;可给出特征重要性（决策树也可以）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;缺点：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;随机森林已经被证明在某些噪音（存在着错误或异常(偏离期望值)的数据）较大的分类或者回归问题上会过拟合。&lt;/li&gt;
  &lt;li&gt;随机可能导致很多相似的决策树，影响真实结果。&lt;/li&gt;
  &lt;li&gt;不适合处理特征较少的数据，结果可能会不好。&lt;/li&gt;
  &lt;li&gt;比单棵决策树慢。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总之，随机森林是一种适合处理多维（多特征）数据、不平衡、特征遗失数据的优秀分类和回归算法。&lt;/p&gt;

&lt;p&gt;———本文结束&lt;/p&gt;

&lt;p&gt;［参考文档］&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Sakura55/article/details/81413036#11-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%8E%86%E5%8F%B2&quot;&gt;https://blog.csdn.net/Sakura55/article/details/81413036#11-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%8E%86%E5%8F%B2&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/d4b32cccd747&quot;&gt;https://www.jianshu.com/p/d4b32cccd747&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>by 王勤晓</name></author><summary type="html">随机森林（Random Forest，简称RF）是十大经典数据挖掘／机器学习算法，用于分类和回归。本文主要讨论分类。</summary></entry><entry><title type="html">MVX 模式</title><link href="http://localhost:4000/jekyll/update/2019/08/17/MVX.html" rel="alternate" type="text/html" title="MVX 模式" /><published>2019-08-17T19:30:00+08:00</published><updated>2019-08-17T19:30:00+08:00</updated><id>http://localhost:4000/jekyll/update/2019/08/17/MVX</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2019/08/17/MVX.html">&lt;p&gt;软件开发工作者经常会听到MVC，MVP，MVVM框架。这些MVX框架，不是具体的工程技术，而是一种软件设计的模式，将软件项目的开发从逻辑上分层，体现了软件工程中模块化和解藕的思想。&lt;/p&gt;

&lt;p&gt;众多MVX框架，都源于MVC，或者说是MVC的变种。&lt;/p&gt;

&lt;h3 id=&quot;mvc&quot;&gt;MVC&lt;/h3&gt;

&lt;p&gt;MVC（Model-View-Controller, 模型-视图-控制器）。MVC模式最早出现在Java领域，随后衍生到前端开发等领域。&lt;/p&gt;

&lt;p&gt;MVC模式认为一个软件项目的代码在逻辑组织上应该分为三层，分别是模型层（M），视图层（V），控制器层（C）。模型层提供数据输入，视图层展示输出结果，控制器层进行逻辑处理。三层彼此独立，依靠接口通信。这种设计模式，避免不同逻辑层耦合，某一层的修改不涉及其他层的修改，其修改对其他层也不可见。这种设计让代码开发和维护起来更简单。&lt;/p&gt;

&lt;p&gt;MVC模式中各层的通信是单向的。一般是V或者用户发出请求给＝＝》C，然后C通知＝＝》M要准备哪些数据，M准备数据并发送给＝＝》V。&lt;/p&gt;

&lt;h3 id=&quot;mvp&quot;&gt;MVP&lt;/h3&gt;

&lt;p&gt;MVP（Model-View-Presenter, 模型-视图-呈现器）。MVP在MVC的基础上改进，与MVC的不同是1）Contrller变成了Presenter，2）各层的通信变成了双向，3）V与M不再直接联系，所有通信经过P处理。减轻了View层的工作，对应增加了Presenter层的工作。&lt;/p&gt;

&lt;h3 id=&quot;mvvm&quot;&gt;MVVM&lt;/h3&gt;

&lt;p&gt;MVVM（Model-View-ViewModel, 模型-视图-视图模型）。MVVM进一步在MVP的基础上改进，与MVP的不同是1）Presenter变成了ViewModel，2）V与VM双向绑定，一方的变动会自动同步到另一方。&lt;/p&gt;

&lt;p&gt;现在的主流前端框架如Angualr就是采用MVVM模式。MVVM的设计思想：关注Js对象（Model）的变化，让MVVM框架去自动更新DOM（View）的状态，从而把开发者从操作DOM的繁琐步骤中解脱出来。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;我的理解：MVC，MVP还是MVVM的差异主要实在各层的分工上，无非是V层厚一点，或者C层工作职责多一点，具体的场景选什么看需求。但MVX核心思想没有变，那就是模块化和解藕，这是在任何软件项目开发中都应该遵循的原则。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;———本文结束&lt;/p&gt;

&lt;p&gt;［参考文档］&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.ruanyifeng.com/blog/2015/02/mvcmvp_mvvm.html&quot;&gt;http://www.ruanyifeng.com/blog/2015/02/mvcmvp_mvvm.html&lt;/a&gt;
&lt;a href=&quot;https://www.liaoxuefeng.com/wiki/1022910821149312/1108898947791072&quot;&gt;https://www.liaoxuefeng.com/wiki/1022910821149312/1108898947791072&lt;/a&gt;&lt;/p&gt;</content><author><name>by 王勤晓</name></author><summary type="html">软件开发工作者经常会听到MVC，MVP，MVVM框架。这些MVX框架，不是具体的工程技术，而是一种软件设计的模式，将软件项目的开发从逻辑上分层，体现了软件工程中模块化和解藕的思想。</summary></entry><entry><title type="html">《黑客与画家》句抄</title><link href="http://localhost:4000/jekyll/update/2019/08/10/hackers_and_painters_notes.html" rel="alternate" type="text/html" title="《黑客与画家》句抄" /><published>2019-08-10T16:30:00+08:00</published><updated>2019-08-10T16:30:00+08:00</updated><id>http://localhost:4000/jekyll/update/2019/08/10/hackers_and_painters_notes</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2019/08/10/hackers_and_painters_notes.html">&lt;p&gt;本周没有新的阅读。接&lt;a href=&quot;https://wangqinxiao.github.io/jekyll/update/2019/07/28/why_nerds_are_unpopular_notes.html&quot;&gt;上篇&lt;/a&gt;继续整理下Hackers and Painters（黑客与画家）一书的句子。&lt;/p&gt;

&lt;p&gt;《黑客与画家》是该书中的一篇文章。本文不讨论该文思想，只记录几个有所启发的句子。&lt;/p&gt;

&lt;p&gt;1.&lt;code class=&quot;highlighter-rouge&quot;&gt;The only external test is time. Over time, beautiful things tend to thrive, and ugly things tend to get discarded. Unfortunately, the amounts of time involved can be longer than human lifetimes.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;任何事物的评判都需要一个标准，学术圈靠论文、职场靠KPI、相亲靠高富帅。作者认为黑客的工作更像艺术，难以有客观标准，唯有时间能检验出真理／美，但问题是时间往往会很长。时间的筛选虽然漫长，但无疑都是经典的普世文化。每个人都逃不过时间的宿命，如果能留下点什么有价值的痕迹，不枉此生；如果不能，在有限的时间里阅读时间长河留下的礼物，也是一件美事。&lt;/p&gt;

&lt;p&gt;2.&lt;code class=&quot;highlighter-rouge&quot;&gt;Everyone in the sciences secretly believes that mathematicians are smarter than they are. I think mathematicians also believe this. At any rate, the result is that scientists tend to make their work look as mathematical as possible.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;人们都认为数学家是最聪明的群体。所以科学家们都喜欢把自己的工作变得像数学研究，最直接的体现就是在文章中使用公式和希腊字母。把问题数学抽象是一种归纳的方法，但不少投机之徒利用人们对数学的敬畏，故意制造障碍，以浑水摸鱼或装逼。此现象不可避免，唯一的方法就是自己掌握数学，才能识别出南郭先生。另一方面，如果真想让受众明白自己的表述，就能少用公式就少用，正如霍金曾经说过，“你多写一个公式，就会少一半的读者”。&lt;/p&gt;

&lt;p&gt;3.&lt;code class=&quot;highlighter-rouge&quot;&gt;Empathy is probably the single most important difference between a good hacker and a great one. Some hackers are quite smart, but when it comes to empathy are practically solipsists. It's hard for such people to design great software, because they can't see things from the user's point of view.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;好的黑客和优秀黑客的区别在于是否拥有“同理心”，站在用户的角度思考，才能做出优秀的产品。演讲、写作、处理人际关系、谈恋爱亦如此。&lt;/p&gt;

&lt;p&gt;4.&lt;code class=&quot;highlighter-rouge&quot;&gt;Programs should be written for people to read, and only incidentally for machines to execute.You need to have empathy not just for your users, but for your readers. It's in your interest, because you'll be one of them. Many a hacker has written a program only to find on returning to it six months later that he has no idea how it works. I know several people who've sworn off Perl after such experiences.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;程序是写给人看的，顺便让机器执行。作者认为开发者不仅要对用户有同理心，对程序的读者也要有同理心，这对开发者自己也有利，因为开发者自己也是读者的一份子。开发者如果便写的程序可读性差，可能自己几个月回来也看不懂了，更别说让其他人维护。正如乔布斯对待iPhone，不仅外表设计要完美，内部零件结构也要精益求精，正是这种态度才能造就经得起时间考验的艺术品。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.paulgraham.com/hp.html&quot;&gt;黑客与画家 原文地址&lt;/a&gt;&lt;/p&gt;</content><author><name>by 王勤晓</name></author><summary type="html">本周没有新的阅读。接上篇继续整理下Hackers and Painters（黑客与画家）一书的句子。</summary></entry></feed>
